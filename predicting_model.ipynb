{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C://Users//MathurS1/Desktop/Breath_Test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'age', 'BMI', 'Diagnosis', 'group.Postive H2',\n",
       "       'group.Positive CH4', 'group.Normal BT', 'group.Positive h2 & Ch4',\n",
       "       'group.Flatliner', 'group.Equivocal',\n",
       "       ...\n",
       "       'ICD.252', 'ICD.413', 'ICD.151', 'ICD.410', 'ICD.696', 'ICD.634',\n",
       "       'ICD.695', 'ICD.284', 'ICD.222', 'ICD.694'],\n",
       "      dtype='object', length=109)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_and_output = pd.read_csv(\"input_and_output.csv\")\n",
    "input_and_output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_and_output = input_and_output.drop('Unnamed: 0', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = input_and_output.drop('Diagnosis',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = input_and_output['Diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) age                       0.269846\n",
      " 2) BMI                       0.138996\n",
      " 3) group.Postive H2          0.131695\n",
      " 4) group.Positive CH4        0.126950\n",
      " 5) group.Normal BT           0.093633\n",
      " 6) group.Positive h2 & Ch4   0.042277\n",
      " 7) group.Flatliner           0.013116\n",
      " 8) group.Equivocal           0.012724\n",
      " 9) gender.F                  0.012606\n",
      "10) gender.M                  0.012017\n",
      "11) race.White                0.011855\n",
      "12) race.Black or African American 0.008732\n",
      "13) race.Asian                0.008722\n",
      "14) race.Other                0.005769\n",
      "15) dinf.2                    0.005692\n",
      "16) dinf.0                    0.005167\n",
      "17) dinf.1                    0.005047\n",
      "18) dinf.3                    0.004896\n",
      "19) ICD.174                   0.004829\n",
      "20) ICD.V10                   0.004671\n",
      "21) ICD.244                   0.004588\n",
      "22) ICD.562                   0.004547\n",
      "23) ICD.401                   0.004422\n",
      "24) ICD.724                   0.004083\n",
      "25) ICD.579                   0.003676\n",
      "26) ICD.285                   0.003642\n",
      "27) ICD.530                   0.003042\n",
      "28) ICD.424                   0.002938\n",
      "29) ICD.536                   0.002869\n",
      "30) ICD.414                   0.002553\n",
      "31) ICD.427                   0.002356\n",
      "32) ICD.599                   0.002329\n",
      "33) ICD.692                   0.002226\n",
      "34) ICD.272                   0.002176\n",
      "35) ICD.564                   0.002169\n",
      "36) ICD.346                   0.002160\n",
      "37) ICD.255                   0.002144\n",
      "38) ICD.787                   0.002086\n",
      "39) ICD.331                   0.001915\n",
      "40) ICD.784                   0.001880\n",
      "41) ICD.576                   0.001802\n",
      "42) ICD.211                   0.001722\n",
      "43) ICD.428                   0.001543\n",
      "44) ICD.785                   0.001446\n",
      "45) ICD.733                   0.001429\n",
      "46) ICD.556                   0.001179\n",
      "47) ICD.332                   0.001046\n",
      "48) ICD.648                   0.000997\n",
      "49) ICD.443                   0.000993\n",
      "50) ICD.560                   0.000964\n",
      "51) ICD.305                   0.000928\n",
      "52) ICD.729                   0.000867\n",
      "53) ICD.780                   0.000768\n",
      "54) ICD.250                   0.000711\n",
      "55) ICD.300                   0.000707\n",
      "56) ICD.188                   0.000688\n",
      "57) ICD.429                   0.000664\n",
      "58) ICD.356                   0.000656\n",
      "59) ICD.233                   0.000632\n",
      "60) ICD.242                   0.000567\n",
      "61) ICD.280                   0.000393\n",
      "62) ICD.571                   0.000358\n",
      "63) ICD.256                   0.000346\n",
      "64) ICD.592                   0.000342\n",
      "65) ICD.577                   0.000342\n",
      "66) ICD.281                   0.000078\n",
      "67) ICD.223                   0.000064\n",
      "68) ICD.162                   0.000062\n",
      "69) ICD.574                   0.000060\n",
      "70) ICD.296                   0.000057\n",
      "71) ICD.558                   0.000047\n",
      "72) ICD.282                   0.000045\n",
      "73) ICD.783                   0.000042\n",
      "74) ICD.405                   0.000036\n",
      "75) ICD.V12                   0.000035\n",
      "76) ICD.183                   0.000034\n",
      "77) ICD.307                   0.000028\n",
      "78) ICD.654                   0.000024\n",
      "79) ICD.416                   0.000024\n",
      "80) ICD.658                   0.000023\n",
      "81) ICD.440                   0.000023\n",
      "82) ICD.595                   0.000022\n",
      "83) ICD.153                   0.000020\n",
      "84) ICD.345                   0.000018\n",
      "85) ICD.290                   0.000015\n",
      "86) ICD.637                   0.000015\n",
      "87) ICD.617                   0.000012\n",
      "88) ICD.706                   0.000011\n",
      "89) ICD.217                   0.000011\n",
      "90) ICD.669                   0.000011\n",
      "91) ICD.411                   0.000009\n",
      "92) ICD.200                   0.000007\n",
      "93) ICD.358                   0.000007\n",
      "94) ICD.453                   0.000007\n",
      "95) ICD.180                   0.000007\n",
      "96) ICD.628                   0.000005\n",
      "97) ICD.572                   0.000004\n",
      "98) ICD.252                   0.000001\n",
      "99) ICD.413                   0.000001\n",
      "100) ICD.151                   0.000001\n",
      "101) ICD.410                   0.000001\n",
      "102) ICD.696                   0.000001\n",
      "103) ICD.634                   0.000000\n",
      "104) ICD.695                   0.000000\n",
      "105) ICD.284                   0.000000\n",
      "106) ICD.222                   0.000000\n",
      "107) ICD.694                   0.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "feat_labels = X.columns[0:]\n",
    "\n",
    "#defining our hyperparameters\n",
    "random_forest = RandomForestClassifier(n_estimators=600, random_state=42, n_jobs=-1)\n",
    "\n",
    "#fit \n",
    "random_forest.fit(X_train,y_train)\n",
    "\n",
    "#getting the important features and labels\n",
    "importances = random_forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f+1,25,feat_labels[f],importances[indices[f]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = LinearSVC(random_state=42,multi_class='crammer_singer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=42,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      3184\n",
      "          1       0.84      0.73      0.78        67\n",
      "          2       0.74      0.55      0.63        47\n",
      "\n",
      "avg / total       0.98      0.99      0.98      3298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9857489387507581\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_predictions = random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      3184\n",
      "          1       0.80      0.66      0.72        67\n",
      "          2       0.69      0.43      0.53        47\n",
      "\n",
      "avg / total       0.98      0.98      0.98      3298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,r_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9824135839902971\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,r_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing model optimizations...\n",
      "\n",
      "Estimator: Logistic Regression\n",
      "Best params: {'clf__C': 1.0, 'clf__solver': 'newton-cg'}\n",
      "Best training accuracy: 0.980\n",
      "Test set accuracy score for best params: 0.985 \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      3184\n",
      "          1       0.86      0.72      0.78        67\n",
      "          2       0.75      0.45      0.56        47\n",
      "\n",
      "avg / total       0.98      0.98      0.98      3298\n",
      "\n",
      "\n",
      "Estimator: Random Forest\n",
      "Best params: {'clf__criterion': 'gini', 'clf__max_depth': 5, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2}\n",
      "Best training accuracy: 0.952\n",
      "Test set accuracy score for best params: 0.965 \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      3184\n",
      "          1       0.00      0.00      0.00        67\n",
      "          2       0.00      0.00      0.00        47\n",
      "\n",
      "avg / total       0.93      0.97      0.95      3298\n",
      "\n",
      "\n",
      "Estimator: Support Vector Machine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'clf__C': 0.5}\n",
      "Best training accuracy: 0.980\n",
      "Test set accuracy score for best params: 0.986 \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      3184\n",
      "          1       0.85      0.75      0.79        67\n",
      "          2       0.74      0.55      0.63        47\n",
      "\n",
      "avg / total       0.98      0.99      0.99      3298\n",
      "\n",
      "\n",
      "Classifier with best test set accuracy: Support Vector Machine\n"
     ]
    }
   ],
   "source": [
    "#logisitic regression\n",
    "pipe_lr = Pipeline([('clf', LogisticRegression(random_state=42,multi_class='multinomial'))])\n",
    "\n",
    "#linear SVC\n",
    "pipe_svm = Pipeline([(('clf', LinearSVC(random_state=42,multi_class='crammer_singer')))])\n",
    "\n",
    "pipe_rf = Pipeline([('clf', RandomForestClassifier(random_state=42,n_estimators=300))])\n",
    "\n",
    "\n",
    "\n",
    "#GRID_SEARCH_PARAMETERS\n",
    "\n",
    "param_range = [1, 2, 3, 4, 5]\n",
    "param_range_fl = [1.0, 0.5, 0.1]\n",
    "\n",
    "grid_params_lr = [{'clf__C': param_range_fl,\n",
    "        'clf__solver': ['newton-cg']}] \n",
    "\n",
    "grid_params_rf = [{'clf__criterion': ['gini'],\n",
    "        'clf__min_samples_leaf': param_range,\n",
    "        'clf__max_depth': param_range,\n",
    "        'clf__min_samples_split': param_range[1:]}]\n",
    "\n",
    "grid_params_svc = [{'clf__C': param_range_fl}]\n",
    "\n",
    "\n",
    "# Construct grid searches\n",
    "jobs = -1\n",
    "\n",
    "gs_lr = GridSearchCV(estimator = pipe_lr,param_grid=grid_params_lr,scoring='accuracy',cv=5) \n",
    "\n",
    "gs_rf = GridSearchCV(estimator = pipe_rf,param_grid=grid_params_rf,scoring='accuracy',cv=5, n_jobs=jobs)\n",
    "\n",
    "gs_svc = GridSearchCV(estimator = pipe_svm,param_grid=grid_params_svc,scoring='accuracy',cv=5, n_jobs=jobs)\n",
    "\n",
    "#creating a list of all this for ease of interation\n",
    "\n",
    "grids = [gs_lr,gs_rf,gs_svc]\n",
    "\n",
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "grid_dict = {0: 'Logistic Regression', 1: 'Random Forest', 2: 'Support Vector Machine'}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Fit the grid search objects\n",
    "print('Performing model optimizations...')\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "for idx, gs in enumerate(grids):\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\n",
    "    # Fit grid search\t\n",
    "    gs.fit(X_train, y_train)\n",
    "    # Best params\n",
    "    print('Best params: %s' % gs.best_params_)\n",
    "    # Best training data accuracy\n",
    "    print('Best training accuracy: %.3f' % gs.best_score_)\n",
    "    # Predict on test data with best params\n",
    "    y_pred = gs.predict(X_test)\n",
    "    # Test data accuracy of model with best params\n",
    "    print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    # Track best (highest test accuracy) model\n",
    "    if accuracy_score(y_test, y_pred) > best_acc:\n",
    "        best_acc = accuracy_score(y_test, y_pred)\n",
    "        best_gs = gs\n",
    "        best_clf = idx\n",
    "print('\\nClassifier with best test set accuracy: %s' % grid_dict[best_clf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      3184\n",
      "          1       0.33      0.01      0.03        67\n",
      "          2       0.40      0.04      0.08        47\n",
      "\n",
      "avg / total       0.95      0.96      0.95      3298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "## Instantiate the model with 5 neighbors. \n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "## Fit the model on the training data.\n",
    "knn.fit(X_train, y_train)\n",
    "## See how the model performs on the test data.\n",
    "\n",
    "knn_predictions = knn.predict(X_test)\n",
    "print(classification_report(y_test,knn_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "CD_and_UC = pd.read_csv(\"CD_UC_ML.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "CD_and_UC = CD_and_UC.drop('Unnamed: 0',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = CD_and_UC.drop('Diagnosis',1)\n",
    "\n",
    "y = CD_and_UC['Diagnosis']\n",
    "X = X.drop('X',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_model = SVC(random_state=42)\n",
    "svc_model.fit(X_train,y_train)\n",
    "predictions = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.98      0.77        92\n",
      "          2       0.33      0.02      0.04        54\n",
      "\n",
      "avg / total       0.52      0.62      0.50       146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] C=0.1, gamma=10, kernel=linear ..................................\n",
      "[CV] ................... C=0.1, gamma=10, kernel=linear, total=  26.4s\n",
      "[CV] C=0.1, gamma=10, kernel=linear ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   26.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=0.1, gamma=10, kernel=linear, total=  31.1s\n",
      "[CV] C=0.1, gamma=10, kernel=linear ..................................\n",
      "[CV] ................... C=0.1, gamma=10, kernel=linear, total=  36.8s\n",
      "[CV] C=0.1, gamma=10, kernel=rbf .....................................\n",
      "[CV] ...................... C=0.1, gamma=10, kernel=rbf, total=   0.0s\n",
      "[CV] C=0.1, gamma=10, kernel=rbf .....................................\n",
      "[CV] ...................... C=0.1, gamma=10, kernel=rbf, total=   0.0s\n",
      "[CV] C=0.1, gamma=10, kernel=rbf .....................................\n",
      "[CV] ...................... C=0.1, gamma=10, kernel=rbf, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV] .................... C=0.1, gamma=1, kernel=linear, total=  26.5s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV] .................... C=0.1, gamma=1, kernel=linear, total=  31.3s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV] .................... C=0.1, gamma=1, kernel=linear, total=  36.7s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV] .................. C=0.1, gamma=0.1, kernel=linear, total=  26.2s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV] .................. C=0.1, gamma=0.1, kernel=linear, total=  30.4s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV] .................. C=0.1, gamma=0.1, kernel=linear, total=  36.7s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=0.1, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=0.1, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=0.1, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV] ................. C=0.1, gamma=0.01, kernel=linear, total=  26.2s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV] ................. C=0.1, gamma=0.01, kernel=linear, total=  30.5s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV] ................. C=0.1, gamma=0.01, kernel=linear, total=  36.9s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=0.1, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=0.1, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=0.1, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ................ C=0.1, gamma=0.001, kernel=linear, total=  26.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ................ C=0.1, gamma=0.001, kernel=linear, total=  31.3s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ................ C=0.1, gamma=0.001, kernel=linear, total=  36.9s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=0.1, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=0.1, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=0.1, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=10, kernel=linear ....................................\n",
      "[CV] ..................... C=1, gamma=10, kernel=linear, total=  24.9s\n",
      "[CV] C=1, gamma=10, kernel=linear ....................................\n",
      "[CV] ..................... C=1, gamma=10, kernel=linear, total=  24.6s\n",
      "[CV] C=1, gamma=10, kernel=linear ....................................\n",
      "[CV] ..................... C=1, gamma=10, kernel=linear, total=  41.7s\n",
      "[CV] C=1, gamma=10, kernel=rbf .......................................\n",
      "[CV] ........................ C=1, gamma=10, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=10, kernel=rbf .......................................\n",
      "[CV] ........................ C=1, gamma=10, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=10, kernel=rbf .......................................\n",
      "[CV] ........................ C=1, gamma=10, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ...................... C=1, gamma=1, kernel=linear, total=  24.8s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ...................... C=1, gamma=1, kernel=linear, total=  24.1s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ...................... C=1, gamma=1, kernel=linear, total=  43.8s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=1, gamma=1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=1, gamma=1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=1, gamma=1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] .................... C=1, gamma=0.1, kernel=linear, total=  24.8s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] .................... C=1, gamma=0.1, kernel=linear, total=  23.7s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] .................... C=1, gamma=0.1, kernel=linear, total=  41.7s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ................... C=1, gamma=0.01, kernel=linear, total=  24.7s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ................... C=1, gamma=0.01, kernel=linear, total=  23.7s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ................... C=1, gamma=0.01, kernel=linear, total=  41.9s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=0.001, kernel=linear, total=  24.5s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=0.001, kernel=linear, total=  24.1s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=0.001, kernel=linear, total=  41.1s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=10, kernel=linear ...................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, gamma=10, kernel=linear, total=  53.0s\n",
      "[CV] C=10, gamma=10, kernel=linear ...................................\n",
      "[CV] .................... C=10, gamma=10, kernel=linear, total=  52.5s\n",
      "[CV] C=10, gamma=10, kernel=linear ...................................\n",
      "[CV] .................... C=10, gamma=10, kernel=linear, total=  46.8s\n",
      "[CV] C=10, gamma=10, kernel=rbf ......................................\n",
      "[CV] ....................... C=10, gamma=10, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=10, kernel=rbf ......................................\n",
      "[CV] ....................... C=10, gamma=10, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=10, kernel=rbf ......................................\n",
      "[CV] ....................... C=10, gamma=10, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ..................... C=10, gamma=1, kernel=linear, total=  52.4s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ..................... C=10, gamma=1, kernel=linear, total=  51.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ..................... C=10, gamma=1, kernel=linear, total=  48.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........................ C=10, gamma=1, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........................ C=10, gamma=1, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........................ C=10, gamma=1, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ................... C=10, gamma=0.1, kernel=linear, total=  56.6s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ................... C=10, gamma=0.1, kernel=linear, total=  53.7s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ................... C=10, gamma=0.1, kernel=linear, total=  49.3s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV] .................. C=10, gamma=0.01, kernel=linear, total=  54.8s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV] .................. C=10, gamma=0.01, kernel=linear, total=  50.7s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV] .................. C=10, gamma=0.01, kernel=linear, total=  46.2s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ..................... C=10, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] ................. C=10, gamma=0.001, kernel=linear, total=  53.8s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] ................. C=10, gamma=0.001, kernel=linear, total=  54.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] ................. C=10, gamma=0.001, kernel=linear, total=  49.2s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=10, kernel=linear ..................................\n",
      "[CV] ................... C=100, gamma=10, kernel=linear, total=  59.8s\n",
      "[CV] C=100, gamma=10, kernel=linear ..................................\n",
      "[CV] ................... C=100, gamma=10, kernel=linear, total= 4.3min\n",
      "[CV] C=100, gamma=10, kernel=linear ..................................\n",
      "[CV] ................... C=100, gamma=10, kernel=linear, total=  39.1s\n",
      "[CV] C=100, gamma=10, kernel=rbf .....................................\n",
      "[CV] ...................... C=100, gamma=10, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=10, kernel=rbf .....................................\n",
      "[CV] ...................... C=100, gamma=10, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=10, kernel=rbf .....................................\n",
      "[CV] ...................... C=100, gamma=10, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV] .................... C=100, gamma=1, kernel=linear, total= 1.0min\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV] .................... C=100, gamma=1, kernel=linear, total= 4.0min\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV] .................... C=100, gamma=1, kernel=linear, total=  37.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] ....................... C=100, gamma=1, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] ....................... C=100, gamma=1, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] ....................... C=100, gamma=1, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV] .................. C=100, gamma=0.1, kernel=linear, total=  59.3s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV] .................. C=100, gamma=0.1, kernel=linear, total= 4.3min\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV] .................. C=100, gamma=0.1, kernel=linear, total=  38.9s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=100, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=100, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... C=100, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
      "[CV] ................. C=100, gamma=0.01, kernel=linear, total= 1.0min\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
      "[CV] ................. C=100, gamma=0.01, kernel=linear, total= 4.2min\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
      "[CV] ................. C=100, gamma=0.01, kernel=linear, total=  37.2s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=100, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=100, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] .................... C=100, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ................ C=100, gamma=0.001, kernel=linear, total=  59.2s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ................ C=100, gamma=0.001, kernel=linear, total= 4.1min\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ................ C=100, gamma=0.001, kernel=linear, total=  37.2s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=10, kernel=linear .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=1000, gamma=10, kernel=linear, total= 2.3min\n",
      "[CV] C=1000, gamma=10, kernel=linear .................................\n",
      "[CV] .................. C=1000, gamma=10, kernel=linear, total=  44.0s\n",
      "[CV] C=1000, gamma=10, kernel=linear .................................\n",
      "[CV] .................. C=1000, gamma=10, kernel=linear, total=  50.3s\n",
      "[CV] C=1000, gamma=10, kernel=rbf ....................................\n",
      "[CV] ..................... C=1000, gamma=10, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=10, kernel=rbf ....................................\n",
      "[CV] ..................... C=1000, gamma=10, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=10, kernel=rbf ....................................\n",
      "[CV] ..................... C=1000, gamma=10, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
      "[CV] ................... C=1000, gamma=1, kernel=linear, total= 2.2min\n",
      "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
      "[CV] ................... C=1000, gamma=1, kernel=linear, total=  38.6s\n",
      "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
      "[CV] ................... C=1000, gamma=1, kernel=linear, total=  47.8s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ...................... C=1000, gamma=1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ...................... C=1000, gamma=1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ...................... C=1000, gamma=1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
      "[CV] ................. C=1000, gamma=0.1, kernel=linear, total= 2.2min\n",
      "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
      "[CV] ................. C=1000, gamma=0.1, kernel=linear, total=  39.6s\n",
      "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
      "[CV] ................. C=1000, gamma=0.1, kernel=linear, total=  47.8s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] .................... C=1000, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] .................... C=1000, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] .................... C=1000, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
      "[CV] ................ C=1000, gamma=0.01, kernel=linear, total= 2.2min\n",
      "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
      "[CV] ................ C=1000, gamma=0.01, kernel=linear, total=  40.3s\n",
      "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
      "[CV] ................ C=1000, gamma=0.01, kernel=linear, total=  49.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ................... C=1000, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ................... C=1000, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ................... C=1000, gamma=0.01, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
      "[CV] ............... C=1000, gamma=0.001, kernel=linear, total= 2.2min\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
      "[CV] ............... C=1000, gamma=0.001, kernel=linear, total=  43.3s\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
      "[CV] ............... C=1000, gamma=0.001, kernel=linear, total=  49.9s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=0.001, kernel=rbf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed: 76.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.1, 1, 10, 100, 1000], 'gamma': [10, 1, 0.1, 0.01, 0.001], 'kernel': ['linear', 'rbf']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C':[0.1,1,10,100,1000],'gamma':[10,1,0.1,0.01,0.001],'kernel':['linear','rbf']}\n",
    "grid = GridSearchCV(SVC(),param_grid,verbose=2)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'gamma': 10, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_perdictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.93      0.85        92\n",
      "          2       0.83      0.54      0.65        54\n",
      "\n",
      "avg / total       0.79      0.79      0.77       146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,grid_perdictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.86      0.96      0.91        96\n",
      "          2       0.90      0.70      0.79        50\n",
      "\n",
      "avg / total       0.87      0.87      0.87       146\n",
      "\n",
      "0.8698630136986302\n"
     ]
    }
   ],
   "source": [
    "#SVC\n",
    "\n",
    "\n",
    "svc_model = SVC(C=0.1,gamma=10,kernel='linear')\n",
    "svc_model.fit(X_train,y_train)\n",
    "svc_predictions = svc_model.predict(X_test)\n",
    "print(classification_report(y_test,svc_predictions))\n",
    "print(accuracy_score(y_test,svc_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.93      0.80        96\n",
      "          2       0.63      0.24      0.35        50\n",
      "\n",
      "avg / total       0.68      0.69      0.64       146\n",
      "\n",
      "0.6917808219178082\n"
     ]
    }
   ],
   "source": [
    "##KNN\n",
    "training_accuracy =[]\n",
    "testing_accuracy=[]\n",
    "neighbours_setting = range(1,11)\n",
    "\n",
    "# for n_neigbors in neighbours_setting:\n",
    "#     knn = KNeighborsClassifier(n_neighbors=n_neigbors)\n",
    "#     knn.fit(X_train,y_train)\n",
    "#     testing_accuracy.append(knn.score(X_train,y_train))\n",
    "    \n",
    "# plt.plot(neighbours_setting,testing_accuracy,label = \"testing accuracy\")\n",
    "# plt.xlabel(\"n-neighbours\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "\n",
    "# plt.legend()\n",
    "# plt.savefig('knn')\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "# ## Fit the model on the training data.\n",
    "knn.fit(X_train, y_train)\n",
    "# ## See how the model performs on the test data.\n",
    "\n",
    "# knn_predictions = knn.predict(X_test)\n",
    "print(classification_report(y_test,knn_predictions))\n",
    "print(accuracy_score(y_test,knn_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.86      0.96      0.91        96\n",
      "          2       0.90      0.70      0.79        50\n",
      "\n",
      "avg / total       0.87      0.87      0.87       146\n",
      "\n",
      "0.8698630136986302\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# def f_importances(coef, names):\n",
    "#     imp = coef\n",
    "#     imp,names = zip(*sorted(zip(imp,names)))\n",
    "#     plt.barh(range(len(names)), imp, align='center')\n",
    "#     plt.yticks(range(len(names)), names)\n",
    "#     plt.show()\n",
    "\n",
    "# features_names = ['input1', 'input2']\n",
    "# svc_model = SVC(C=0.1,gamma=10,kernel='linear')\n",
    "# svc_model.fit(X_train,y_train)\n",
    "# f_importances(svc_model.coef_, features_names)\n",
    "\n",
    "\n",
    "#LOGISTIC REGRESSION\n",
    "\n",
    "logres_model = LogisticRegression(C=0.1,penalty='l1')\n",
    "logres_model.fit(X_train,y_train)\n",
    "logres_predictions = logres_model.predict(X_test)\n",
    "print(classification_report(y_test,logres_predictions))\n",
    "print(accuracy_score(y_test,logres_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) age                       0.260683\n",
      " 2) BMI                       0.146877\n",
      " 3) group.Postive.H2          0.125955\n",
      " 4) group.Positive.CH4        0.025777\n",
      " 5) group.Normal.BT           0.024735\n",
      " 6) group.Positive.h2...Ch4   0.020540\n",
      " 7) group.Flatliner           0.020186\n",
      " 8) group.Equivocal           0.019348\n",
      " 9) gender.F                  0.017765\n",
      "10) gender.M                  0.017424\n",
      "11) race.White                0.017399\n",
      "12) race.Black.or.African.American 0.016069\n",
      "13) race.Asian                0.015631\n",
      "14) race.Other                0.013149\n",
      "15) dinf.2                    0.012763\n",
      "16) dinf.0                    0.012075\n",
      "17) dinf.1                    0.011793\n",
      "18) dinf.3                    0.011540\n",
      "19) ICD.174                   0.011279\n",
      "20) ICD.V10                   0.010865\n",
      "21) ICD.244                   0.010816\n",
      "22) ICD.562                   0.010136\n",
      "23) ICD.401                   0.009171\n",
      "24) ICD.724                   0.008608\n",
      "25) ICD.579                   0.008427\n",
      "26) ICD.285                   0.007975\n",
      "27) ICD.530                   0.007963\n",
      "28) ICD.424                   0.007210\n",
      "29) ICD.536                   0.007010\n",
      "30) ICD.414                   0.006756\n",
      "31) ICD.427                   0.006513\n",
      "32) ICD.599                   0.006109\n",
      "33) ICD.692                   0.006098\n",
      "34) ICD.272                   0.005040\n",
      "35) ICD.564                   0.005015\n",
      "36) ICD.346                   0.004769\n",
      "37) ICD.255                   0.004495\n",
      "38) ICD.787                   0.004491\n",
      "39) ICD.331                   0.004404\n",
      "40) ICD.784                   0.004348\n",
      "41) ICD.576                   0.003962\n",
      "42) ICD.211                   0.003906\n",
      "43) ICD.428                   0.003704\n",
      "44) ICD.785                   0.003536\n",
      "45) ICD.733                   0.003399\n",
      "46) ICD.556                   0.003144\n",
      "47) ICD.332                   0.002958\n",
      "48) ICD.648                   0.002872\n",
      "49) ICD.443                   0.002679\n",
      "50) ICD.560                   0.002580\n",
      "51) ICD.305                   0.002338\n",
      "52) ICD.729                   0.002223\n",
      "53) ICD.780                   0.002104\n",
      "54) ICD.250                   0.002083\n",
      "55) ICD.300                   0.002046\n",
      "56) ICD.188                   0.001826\n",
      "57) ICD.429                   0.001322\n",
      "58) ICD.356                   0.001147\n",
      "59) ICD.233                   0.000893\n",
      "60) ICD.242                   0.000862\n",
      "61) ICD.280                   0.000793\n",
      "62) ICD.571                   0.000751\n",
      "63) ICD.256                   0.000721\n",
      "64) ICD.592                   0.000533\n",
      "65) ICD.577                   0.000410\n",
      "66) ICD.281                   0.000000\n",
      "67) ICD.223                   0.000000\n",
      "68) ICD.162                   0.000000\n",
      "69) ICD.574                   0.000000\n",
      "70) ICD.296                   0.000000\n",
      "71) ICD.558                   0.000000\n",
      "72) ICD.282                   0.000000\n",
      "73) ICD.783                   0.000000\n",
      "74) ICD.405                   0.000000\n",
      "75) ICD.V12                   0.000000\n",
      "76) ICD.183                   0.000000\n",
      "77) ICD.307                   0.000000\n",
      "78) ICD.654                   0.000000\n",
      "79) ICD.416                   0.000000\n",
      "80) ICD.658                   0.000000\n",
      "81) ICD.440                   0.000000\n",
      "82) ICD.595                   0.000000\n",
      "83) ICD.153                   0.000000\n",
      "84) ICD.345                   0.000000\n",
      "85) ICD.290                   0.000000\n",
      "86) ICD.637                   0.000000\n",
      "87) ICD.617                   0.000000\n",
      "88) ICD.706                   0.000000\n",
      "89) ICD.217                   0.000000\n",
      "90) ICD.669                   0.000000\n",
      "91) ICD.411                   0.000000\n",
      "92) ICD.200                   0.000000\n",
      "93) ICD.358                   0.000000\n",
      "94) ICD.453                   0.000000\n",
      "95) ICD.180                   0.000000\n",
      "96) ICD.628                   0.000000\n",
      "97) ICD.572                   0.000000\n",
      "98) ICD.252                   0.000000\n",
      "99) ICD.413                   0.000000\n",
      "100) ICD.151                   0.000000\n",
      "101) ICD.410                   0.000000\n",
      "102) ICD.696                   0.000000\n",
      "103) ICD.634                   0.000000\n",
      "104) ICD.695                   0.000000\n",
      "105) ICD.284                   0.000000\n",
      "106) ICD.222                   0.000000\n",
      "107) ICD.694                   0.000000\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST\n",
    "# X.columns[0:]\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "feat_labels = X.columns[0:]\n",
    "\n",
    "#defining our hyperparameters\n",
    "random_forest = RandomForestClassifier(n_estimators=1000, random_state=42, n_jobs=-1)\n",
    "\n",
    "#fit \n",
    "random_forest.fit(X_train,y_train)\n",
    "\n",
    "#getting the important features and labels\n",
    "importances = random_forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f+1,25,feat_labels[f],importances[indices[f]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.86      0.91      0.88        96\n",
      "          2       0.80      0.72      0.76        50\n",
      "\n",
      "avg / total       0.84      0.84      0.84       146\n",
      "\n",
      "0.8424657534246576\n"
     ]
    }
   ],
   "source": [
    "rf_predctions = random_forest.predict(X_test)\n",
    "print(classification_report(y_test,rf_predctions))\n",
    "print(accuracy_score(y_test,rf_predctions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "CD_and_UC = pd.read_csv(\"CD_UC_ML.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l1\n",
      "Best C: 1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.35      0.14      0.20        44\n",
      "          1       0.71      0.89      0.79       102\n",
      "\n",
      "avg / total       0.60      0.66      0.61       146\n",
      "\n",
      "0.6643835616438356\n"
     ]
    }
   ],
   "source": [
    "X = CD_and_UC.drop(['Diagnosis','Unnamed: 0'],1)\n",
    "y = CD_and_UC[\"Diagnosis\"]\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "\n",
    "# Create logistic regression\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "# Create grid search using 5-fold cross validation\n",
    "clf = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "\n",
    "# Fit grid search\n",
    "best_model = clf.fit(X_train,y_train)\n",
    "\n",
    "# View best hyperparameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
    "\n",
    "\n",
    "logres_model = LogisticRegression(C=1.0,penalty='l1')\n",
    "logres_model.fit(X_train,y_train)\n",
    "\n",
    "logres_model_predictions = logres_model.predict(X_test)\n",
    "print(classification_report(y_test,logres_model_predictions))\n",
    "print(accuracy_score(y_test,logres_model_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.02      0.04        44\n",
      "          1       0.70      0.98      0.82       102\n",
      "\n",
      "avg / total       0.59      0.69      0.58       146\n",
      "\n",
      "0.6917808219178082\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(C=1,gamma=10,kernel='linear')\n",
    "svc_model.fit(X_train,y_train)\n",
    "svc_predictions = svc_model.predict(X_test)\n",
    "print(classification_report(y_test,svc_predictions))\n",
    "print(accuracy_score(y_test,svc_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00619939  0.0259974   0.01277971  0.          0.          0.11571751\n",
      "  -0.00744877  0.          0.          0.01471577  0.         -0.73124159\n",
      "   0.          0.42640501  0.61876364]]\n"
     ]
    }
   ],
   "source": [
    "print(logres_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) age                       0.524300\n",
      " 2) BMI                       0.314677\n",
      " 3) group.Normal BT           0.018938\n",
      " 4) group.Positive h2 & Ch4   0.017570\n",
      " 5) group.Postive H2          0.017206\n",
      " 6) group.Flatliner           0.014414\n",
      " 7) group.Positive CH4        0.014383\n",
      " 8) group.Equivocal           0.014008\n",
      " 9) gender.F                  0.013054\n",
      "10) gender.M                  0.012257\n",
      "11) race.White                0.010288\n",
      "12) race.Asian                0.009652\n",
      "13) race.Other                0.007703\n",
      "14) race.Unknown              0.006288\n",
      "15) race.Black or African American 0.005262\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST\n",
    "# X.columns[0:]\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "feat_labels = X.columns[0:]\n",
    "\n",
    "#defining our hyperparameters\n",
    "random_forest = RandomForestClassifier(n_estimators=1000, random_state=42, n_jobs=-1)\n",
    "\n",
    "#fit \n",
    "random_forest.fit(X_train,y_train)\n",
    "\n",
    "#getting the important features and labels\n",
    "importances = random_forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f+1,25,feat_labels[f],importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.30      0.39      0.34        44\n",
      "          1       0.70      0.62      0.66       102\n",
      "\n",
      "avg / total       0.58      0.55      0.56       146\n",
      "\n",
      "0.547945205479452\n"
     ]
    }
   ],
   "source": [
    "rf_predctions = random_forest.predict(X_test)\n",
    "print(classification_report(y_test,rf_predctions))\n",
    "print(accuracy_score(y_test,rf_predctions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "LogisticRegression average accuracy: 0.613 (+/-0.018)\n",
      "LogisticRegression average log_loss: 0.670 (+/-0.016)\n",
      "LogisticRegression average auc: 0.525 (+/-0.098)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scoring = {'accuracy': 'accuracy', 'log_loss': 'neg_log_loss', 'auc': 'roc_auc'}\n",
    "\n",
    "modelCV = LogisticRegression(C=1.0,penalty='l1')\n",
    "\n",
    "results = cross_validate(modelCV, X, y, cv=10, scoring=list(scoring.values()), \n",
    "                         return_train_score=False)\n",
    "\n",
    "print('K-fold cross-validation results:')\n",
    "for sc in range(len(scoring)):\n",
    "    print(modelCV.__class__.__name__+\" average %s: %.3f (+/-%.3f)\" % (list(scoring.keys())[sc], -results['test_%s' % list(scoring.values())[sc]].mean()\n",
    "                               if list(scoring.values())[sc]=='neg_log_loss' \n",
    "                               else results['test_%s' % list(scoring.values())[sc]].mean(), \n",
    "                               results['test_%s' % list(scoring.values())[sc]].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.652469\n",
      "         Iterations 6\n",
      "                               Results: Logit\n",
      "=============================================================================\n",
      "Model:                    Logit                No. Iterations:       6.0000  \n",
      "Dependent Variable:       Diagnosis            Pseudo R-squared:     0.022   \n",
      "Date:                     2018-07-03 14:05     AIC:                  660.1998\n",
      "No. Observations:         486                  BIC:                  714.6205\n",
      "Df Model:                 12                   Log-Likelihood:       -317.10 \n",
      "Df Residuals:             473                  LL-Null:              -324.31 \n",
      "Converged:                1.0000               Scale:                1.0000  \n",
      "-----------------------------------------------------------------------------\n",
      "                                Coef.  Std.Err.    z    P>|z|   [0.025 0.975]\n",
      "-----------------------------------------------------------------------------\n",
      "age                            -0.0078   0.0062 -1.2666 0.2053 -0.0199 0.0043\n",
      "BMI                             0.0063   0.0226  0.2771 0.7817 -0.0380 0.0505\n",
      "group.Normal BT                 0.2288      nan     nan    nan     nan    nan\n",
      "group.Positive h2 & Ch4        -0.1531      nan     nan    nan     nan    nan\n",
      "group.Postive H2                0.2663      nan     nan    nan     nan    nan\n",
      "group.Flatliner                 0.2596      nan     nan    nan     nan    nan\n",
      "group.Positive CH4             -0.1889      nan     nan    nan     nan    nan\n",
      "group.Equivocal                 0.1727      nan     nan    nan     nan    nan\n",
      "gender.F                        0.3223      nan     nan    nan     nan    nan\n",
      "gender.M                        0.2632      nan     nan    nan     nan    nan\n",
      "race.White                      0.0493      nan     nan    nan     nan    nan\n",
      "race.Asian                     -1.4817      nan     nan    nan     nan    nan\n",
      "race.Other                     -0.0308      nan     nan    nan     nan    nan\n",
      "race.Unknown                    0.6172      nan     nan    nan     nan    nan\n",
      "race.Black or African American  1.4315      nan     nan    nan     nan    nan\n",
      "=============================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:1029: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(np.diag(self.cov_params()))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation average accuracy: 0.611\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "modelCV = LogisticRegression(C=0.01,penalty='l1')\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(modelCV, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "print(\"10-fold cross validation average accuracy: %.3f\" % (results.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_BT = pd.read_csv(\"only_BT_classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=only_BT[\"Diagnosis\"]\n",
    "X = only_BT.drop('Diagnosis',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop('Unnamed: 0',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group.Equivocal</th>\n",
       "      <th>group.Flatliner</th>\n",
       "      <th>group.Normal BT</th>\n",
       "      <th>group.Positive h2 &amp; Ch4</th>\n",
       "      <th>group.Positive CH4</th>\n",
       "      <th>group.Postive H2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     group.Equivocal  group.Flatliner  group.Normal BT  \\\n",
       "290                0                0                0   \n",
       "177                0                0                1   \n",
       "258                0                0                0   \n",
       "294                0                0                0   \n",
       "475                0                1                0   \n",
       "48                 0                0                1   \n",
       "270                0                0                1   \n",
       "55                 0                0                0   \n",
       "241                0                0                0   \n",
       "432                0                0                1   \n",
       "8                  0                0                0   \n",
       "307                0                0                0   \n",
       "237                0                0                1   \n",
       "324                0                0                0   \n",
       "456                0                0                1   \n",
       "451                0                0                1   \n",
       "169                0                0                0   \n",
       "413                0                0                0   \n",
       "327                0                0                0   \n",
       "467                0                0                0   \n",
       "225                0                0                0   \n",
       "199                0                0                1   \n",
       "441                0                0                1   \n",
       "390                0                0                1   \n",
       "419                0                0                1   \n",
       "76                 0                0                1   \n",
       "249                0                0                1   \n",
       "416                0                1                0   \n",
       "64                 0                0                1   \n",
       "46                 0                0                0   \n",
       "..               ...              ...              ...   \n",
       "474                0                1                0   \n",
       "313                0                0                1   \n",
       "149                0                0                1   \n",
       "289                0                0                1   \n",
       "112                0                0                1   \n",
       "32                 0                0                1   \n",
       "426                1                0                0   \n",
       "263                0                0                1   \n",
       "183                0                0                1   \n",
       "174                0                0                1   \n",
       "107                0                0                0   \n",
       "105                0                0                0   \n",
       "206                0                0                1   \n",
       "363                0                0                0   \n",
       "172                0                0                0   \n",
       "410                0                0                1   \n",
       "444                0                0                1   \n",
       "252                0                0                1   \n",
       "400                0                0                0   \n",
       "333                0                0                0   \n",
       "33                 0                0                1   \n",
       "478                0                0                1   \n",
       "253                0                0                0   \n",
       "27                 0                0                1   \n",
       "125                0                0                0   \n",
       "21                 0                0                1   \n",
       "306                0                0                1   \n",
       "20                 0                0                1   \n",
       "315                1                0                0   \n",
       "106                0                0                0   \n",
       "\n",
       "     group.Positive h2 & Ch4  group.Positive CH4  group.Postive H2  \n",
       "290                        0                   0                 1  \n",
       "177                        0                   0                 0  \n",
       "258                        0                   0                 1  \n",
       "294                        0                   0                 1  \n",
       "475                        0                   0                 0  \n",
       "48                         0                   0                 0  \n",
       "270                        0                   0                 0  \n",
       "55                         0                   0                 1  \n",
       "241                        0                   0                 1  \n",
       "432                        0                   0                 0  \n",
       "8                          0                   0                 1  \n",
       "307                        0                   0                 1  \n",
       "237                        0                   0                 0  \n",
       "324                        0                   0                 1  \n",
       "456                        0                   0                 0  \n",
       "451                        0                   0                 0  \n",
       "169                        0                   0                 1  \n",
       "413                        0                   1                 0  \n",
       "327                        0                   0                 1  \n",
       "467                        0                   0                 1  \n",
       "225                        0                   0                 1  \n",
       "199                        0                   0                 0  \n",
       "441                        0                   0                 0  \n",
       "390                        0                   0                 0  \n",
       "419                        0                   0                 0  \n",
       "76                         0                   0                 0  \n",
       "249                        0                   0                 0  \n",
       "416                        0                   0                 0  \n",
       "64                         0                   0                 0  \n",
       "46                         0                   0                 1  \n",
       "..                       ...                 ...               ...  \n",
       "474                        0                   0                 0  \n",
       "313                        0                   0                 0  \n",
       "149                        0                   0                 0  \n",
       "289                        0                   0                 0  \n",
       "112                        0                   0                 0  \n",
       "32                         0                   0                 0  \n",
       "426                        0                   0                 0  \n",
       "263                        0                   0                 0  \n",
       "183                        0                   0                 0  \n",
       "174                        0                   0                 0  \n",
       "107                        0                   0                 1  \n",
       "105                        0                   0                 1  \n",
       "206                        0                   0                 0  \n",
       "363                        0                   0                 1  \n",
       "172                        0                   0                 1  \n",
       "410                        0                   0                 0  \n",
       "444                        0                   0                 0  \n",
       "252                        0                   0                 0  \n",
       "400                        0                   0                 1  \n",
       "333                        0                   0                 1  \n",
       "33                         0                   0                 0  \n",
       "478                        0                   0                 0  \n",
       "253                        0                   0                 1  \n",
       "27                         0                   0                 0  \n",
       "125                        0                   0                 1  \n",
       "21                         0                   0                 0  \n",
       "306                        0                   0                 0  \n",
       "20                         0                   0                 0  \n",
       "315                        0                   0                 0  \n",
       "106                        0                   0                 1  \n",
       "\n",
       "[146 rows x 6 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l1\n",
      "Best C: 1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        55\n",
      "          1       0.62      1.00      0.77        91\n",
      "\n",
      "avg / total       0.39      0.62      0.48       146\n",
      "\n",
      "0.6232876712328768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Create logistic regression\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "# Create grid search using 5-fold cross validation\n",
    "clf = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "\n",
    "# Fit grid search\n",
    "best_model = clf.fit(X_train,y_train)\n",
    "\n",
    "# View best hyperparameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
    "\n",
    "\n",
    "logres_model = LogisticRegression(C=10,penalty='l1')\n",
    "logres_model.fit(X_train,y_train)\n",
    "\n",
    "logres_model_predictions = logres_model.predict(X_test)\n",
    "print(classification_report(y_test,logres_model_predictions))\n",
    "print(accuracy_score(y_test,logres_model_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        48\n",
      "          1       0.67      1.00      0.80        98\n",
      "\n",
      "avg / total       0.45      0.67      0.54       146\n",
      "\n",
      "0.6712328767123288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(C=10,gamma=10,kernel='linear')\n",
    "svc_model.fit(X_train,y_train)\n",
    "svc_predictions = svc_model.predict(X_test)\n",
    "print(classification_report(y_test,svc_predictions))\n",
    "print(accuracy_score(y_test,svc_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_BT_model = pd.read_csv(\"Only_BT_model.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_BT_model = only_BT_model.drop(\"Unnamed: 0\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = only_BT_model['Diagnosis']\n",
    "X = only_BT_model['groups']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1. 1. 4. 1. 4. 4. 4. 4. 4. 4. 1. 4. 5. 1. 4. 1. 1. 4. 4. 4. 1. 1. 1. 4.\n 4. 4. 1. 5. 4. 4. 1. 2. 1. 4. 4. 4. 4. 2. 1. 4. 1. 4. 4. 1. 4. 4. 4. 4.\n 1. 4. 1. 1. 2. 1. 1. 4. 1. 1. 1. 4. 4. 4. 1. 4. 1. 1. 4. 1. 1. 5. 4. 4.\n 4. 1. 4. 4. 1. 4. 4. 4. 4. 4. 1. 4. 1. 1. 5. 1. 4. 4. 1. 1. 4. 1. 4. 1.\n 4. 1. 4. 1. 4. 1. 5. 1. 1. 1. 1. 1. 1. 1. 4. 1. 1. 4. 4. 4. 4. 1. 1. 1.\n 4. 1. 4. 4. 1. 4. 1. 4. 4. 4. 4. 4. 1. 1. 4. 4. 5. 1. 1. 2. 1. 4. 4. 1.\n 4. 2. 1. 1. 1. 1. 4. 1. 4. 5. 1. 1. 1. 4. 4. 4. 4. 5. 4. 4. 1. 4. 4. 1.\n 4. 3. 4. 1. 4. 1. 1. 5. 4. 1. 5. 4. 4. 4. 1. 2. 4. 4. 2. 1. 1. 1. 4. 1.\n 1. 4. 5. 1. 1. 1. 4. 1. 4. 1. 4. 1. 1. 4. 4. 4. 4. 1. 4. 4. 1. 4. 4. 1.\n 5. 2. 1. 4. 1. 4. 5. 4. 4. 4. 1. 1. 4. 2. 1. 4. 4. 5. 1. 6. 1. 4. 4. 1.\n 1. 1. 4. 1. 4. 4. 1. 2. 1. 1. 4. 2. 1. 1. 1. 4. 4. 1. 4. 4. 1. 4. 1. 4.\n 2. 4. 1. 4. 4. 4. 4. 2. 4. 1. 4. 1. 4. 1. 4. 4. 4. 5. 4. 4. 2. 4. 4. 1.\n 1. 1. 1. 1. 4. 1. 1. 1. 4. 1. 4. 6. 1. 1. 1. 1. 1. 4. 1. 4. 4. 1. 4. 1.\n 1. 1. 1. 4. 4. 1. 4. 2. 1. 1. 1. 4. 3. 1. 4. 1. 1. 1. 4. 4. 1. 4. 4. 2.\n 4. 1. 4. 5.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-bdc9a5b722f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msvc_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msvc_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0msvc_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvc_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msvc_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;31m# To ensure that array flags are maintained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1. 1. 4. 1. 4. 4. 4. 4. 4. 4. 1. 4. 5. 1. 4. 1. 1. 4. 4. 4. 1. 1. 1. 4.\n 4. 4. 1. 5. 4. 4. 1. 2. 1. 4. 4. 4. 4. 2. 1. 4. 1. 4. 4. 1. 4. 4. 4. 4.\n 1. 4. 1. 1. 2. 1. 1. 4. 1. 1. 1. 4. 4. 4. 1. 4. 1. 1. 4. 1. 1. 5. 4. 4.\n 4. 1. 4. 4. 1. 4. 4. 4. 4. 4. 1. 4. 1. 1. 5. 1. 4. 4. 1. 1. 4. 1. 4. 1.\n 4. 1. 4. 1. 4. 1. 5. 1. 1. 1. 1. 1. 1. 1. 4. 1. 1. 4. 4. 4. 4. 1. 1. 1.\n 4. 1. 4. 4. 1. 4. 1. 4. 4. 4. 4. 4. 1. 1. 4. 4. 5. 1. 1. 2. 1. 4. 4. 1.\n 4. 2. 1. 1. 1. 1. 4. 1. 4. 5. 1. 1. 1. 4. 4. 4. 4. 5. 4. 4. 1. 4. 4. 1.\n 4. 3. 4. 1. 4. 1. 1. 5. 4. 1. 5. 4. 4. 4. 1. 2. 4. 4. 2. 1. 1. 1. 4. 1.\n 1. 4. 5. 1. 1. 1. 4. 1. 4. 1. 4. 1. 1. 4. 4. 4. 4. 1. 4. 4. 1. 4. 4. 1.\n 5. 2. 1. 4. 1. 4. 5. 4. 4. 4. 1. 1. 4. 2. 1. 4. 4. 5. 1. 6. 1. 4. 4. 1.\n 1. 1. 4. 1. 4. 4. 1. 2. 1. 1. 4. 2. 1. 1. 1. 4. 4. 1. 4. 4. 1. 4. 1. 4.\n 2. 4. 1. 4. 4. 4. 4. 2. 4. 1. 4. 1. 4. 1. 4. 4. 4. 5. 4. 4. 2. 4. 4. 1.\n 1. 1. 1. 1. 4. 1. 1. 1. 4. 1. 4. 6. 1. 1. 1. 1. 1. 4. 1. 4. 4. 1. 4. 1.\n 1. 1. 1. 4. 4. 1. 4. 2. 1. 1. 1. 4. 3. 1. 4. 1. 1. 1. 4. 4. 1. 4. 4. 2.\n 4. 1. 4. 5.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(C=10,gamma=10,kernel='linear')\n",
    "svc_model.fit(X_train,y_train)\n",
    "svc_predictions = svc_model.predict(X_test)\n",
    "print(classification_report(y_test,svc_predictions))\n",
    "print(accuracy_score(y_test,svc_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
